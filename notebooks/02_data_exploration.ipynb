{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üìä Notebook 02: Data Exploration & Analysis\n",
                "\n",
                "**AI Virtual Try-On System - Hybrid Generative AI Approach**\n",
                "\n",
                "---\n",
                "\n",
                "## üìã Notebook Overview\n",
                "\n",
                "This notebook covers comprehensive data exploration for the Virtual Try-On project:\n",
                "\n",
                "1. **Dataset Overview** - Understanding VITON-HD and DeepFashion datasets\n",
                "2. **Data Download** - Scripts to download required datasets\n",
                "3. **Data Structure Analysis** - Explore directory structure and file formats\n",
                "4. **Image Visualization** - Visualize person images, garments, and annotations\n",
                "5. **Statistical Analysis** - Image dimensions, distributions, and quality checks\n",
                "6. **Annotation Exploration** - Parse masks, pose keypoints, and segmentation\n",
                "7. **Data Quality Assessment** - Check for corrupted files and missing data\n",
                "8. **Dataset Splitting** - Prepare train/validation/test splits\n",
                "\n",
                "---\n",
                "\n",
                "## üéØ Learning Objectives\n",
                "\n",
                "By the end of this notebook, you will:\n",
                "- ‚úÖ Understand the structure of VITON-HD dataset\n",
                "- ‚úÖ Know how to download and organize datasets\n",
                "- ‚úÖ Visualize person-garment pairs\n",
                "- ‚úÖ Understand pose annotations and segmentation masks\n",
                "- ‚úÖ Identify data quality issues\n",
                "- ‚úÖ Be ready for data preprocessing\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1Ô∏è‚É£ Setup and Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Standard libraries\n",
                "import os\n",
                "import sys\n",
                "import json\n",
                "import random\n",
                "from pathlib import Path\n",
                "from collections import Counter, defaultdict\n",
                "\n",
                "# Data manipulation\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "\n",
                "# Visualization\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from matplotlib.gridspec import GridSpec\n",
                "\n",
                "# Image processing\n",
                "import cv2\n",
                "from PIL import Image\n",
                "\n",
                "# Progress bars\n",
                "from tqdm.notebook import tqdm\n",
                "\n",
                "# Set random seeds for reproducibility\n",
                "random.seed(42)\n",
                "np.random.seed(42)\n",
                "\n",
                "# Configure matplotlib\n",
                "plt.style.use('seaborn-v0_8-darkgrid')\n",
                "sns.set_palette(\"husl\")\n",
                "%matplotlib inline\n",
                "\n",
                "# Increase figure quality\n",
                "plt.rcParams['figure.dpi'] = 100\n",
                "plt.rcParams['savefig.dpi'] = 300\n",
                "plt.rcParams['figure.figsize'] = (12, 8)\n",
                "\n",
                "print(\"‚úÖ All imports successful!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Set up project paths\n",
                "project_root = Path.cwd().parent\n",
                "data_dir = project_root / 'data'\n",
                "raw_data_dir = data_dir / 'raw'\n",
                "processed_data_dir = data_dir / 'processed'\n",
                "outputs_dir = project_root / 'outputs'\n",
                "\n",
                "print(\"=\"*70)\n",
                "print(\"üìÅ PROJECT PATHS\")\n",
                "print(\"=\"*70)\n",
                "print(f\"Project Root: {project_root}\")\n",
                "print(f\"Data Directory: {data_dir}\")\n",
                "print(f\"Raw Data: {raw_data_dir}\")\n",
                "print(f\"Processed Data: {processed_data_dir}\")\n",
                "print(f\"Outputs: {outputs_dir}\")\n",
                "print(\"=\"*70)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2Ô∏è‚É£ Dataset Overview\n",
                "\n",
                "### VITON-HD Dataset\n",
                "\n",
                "**VITON-HD** is a high-resolution virtual try-on dataset containing:\n",
                "- **13,679 image pairs** (person + garment)\n",
                "- **Resolution**: 1024√ó768 pixels\n",
                "- **Annotations**: Human parsing masks, pose keypoints, dense pose\n",
                "- **Split**: Train (11,647) / Test (2,032)\n",
                "\n",
                "**Dataset Structure:**\n",
                "```\n",
                "VITON-HD/\n",
                "‚îú‚îÄ‚îÄ train/\n",
                "‚îÇ   ‚îú‚îÄ‚îÄ image/           # Person images\n",
                "‚îÇ   ‚îú‚îÄ‚îÄ cloth/           # Garment images\n",
                "‚îÇ   ‚îú‚îÄ‚îÄ image-parse-v3/  # Segmentation masks\n",
                "‚îÇ   ‚îú‚îÄ‚îÄ openpose_img/    # Pose visualizations\n",
                "‚îÇ   ‚îú‚îÄ‚îÄ openpose_json/   # Pose keypoints (JSON)\n",
                "‚îÇ   ‚îî‚îÄ‚îÄ train_pairs.txt  # Image pair mappings\n",
                "‚îî‚îÄ‚îÄ test/\n",
                "    ‚îî‚îÄ‚îÄ [same structure]\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3Ô∏è‚É£ Download Dataset\n",
                "\n",
                "### Option 1: Manual Download\n",
                "\n",
                "1. **VITON-HD**: \n",
                "   - Visit: https://github.com/shadow2496/VITON-HD\n",
                "   - Download from Google Drive link\n",
                "   - Extract to `data/raw/viton-hd/`\n",
                "\n",
                "2. **DeepFashion** (Optional):\n",
                "   - Visit: http://mmlab.ie.cuhk.edu.hk/projects/DeepFashion.html\n",
                "   - Register and download\n",
                "   - Extract to `data/raw/deepfashion/`\n",
                "\n",
                "### Option 2: Automated Download (Using gdown)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install gdown for Google Drive downloads\n",
                "!pip install gdown -q\n",
                "\n",
                "print(\"‚úÖ gdown installed successfully!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import gdown\n",
                "\n",
                "# Create raw data directory\n",
                "viton_hd_dir = raw_data_dir / 'viton-hd'\n",
                "viton_hd_dir.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "print(\"=\"*70)\n",
                "print(\"üì• DATASET DOWNLOAD\")\n",
                "print(\"=\"*70)\n",
                "print(\"\\n‚ö†Ô∏è  Note: VITON-HD dataset is ~15GB. Download may take 30-60 minutes.\")\n",
                "print(\"\\nFor this tutorial, we'll work with a sample dataset first.\")\n",
                "print(\"You can download the full dataset later.\\n\")\n",
                "print(\"=\"*70)\n",
                "\n",
                "# For now, we'll create sample data structure\n",
                "print(\"\\nüí° Creating sample data structure for demonstration...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4Ô∏è‚É£ Create Sample Dataset\n",
                "\n",
                "For demonstration purposes, let's create a sample dataset structure with synthetic data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create sample dataset structure\n",
                "sample_dirs = [\n",
                "    'viton-hd/train/image',\n",
                "    'viton-hd/train/cloth',\n",
                "    'viton-hd/train/image-parse-v3',\n",
                "    'viton-hd/train/openpose_img',\n",
                "    'viton-hd/train/openpose_json',\n",
                "    'viton-hd/test/image',\n",
                "    'viton-hd/test/cloth',\n",
                "    'viton-hd/test/image-parse-v3',\n",
                "    'viton-hd/test/openpose_img',\n",
                "    'viton-hd/test/openpose_json',\n",
                "]\n",
                "\n",
                "for dir_path in sample_dirs:\n",
                "    full_path = raw_data_dir / dir_path\n",
                "    full_path.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "print(\"‚úÖ Sample dataset structure created!\")\n",
                "print(\"\\nüìÅ Created directories:\")\n",
                "for dir_path in sample_dirs[:5]:\n",
                "    print(f\"   - {dir_path}\")\n",
                "print(\"   ...\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Helper function to create sample images\n",
                "def create_sample_person_image(width=768, height=1024):\n",
                "    \"\"\"Create a sample person image with simple shapes\"\"\"\n",
                "    img = np.ones((height, width, 3), dtype=np.uint8) * 240\n",
                "    \n",
                "    # Draw simple person silhouette\n",
                "    # Head\n",
                "    cv2.circle(img, (width//2, height//4), 80, (255, 220, 200), -1)\n",
                "    \n",
                "    # Body\n",
                "    cv2.rectangle(img, (width//2-100, height//4+50), \n",
                "                  (width//2+100, height//2+100), (100, 150, 200), -1)\n",
                "    \n",
                "    # Arms\n",
                "    cv2.rectangle(img, (width//2-180, height//4+80), \n",
                "                  (width//2-100, height//2+50), (255, 200, 180), -1)\n",
                "    cv2.rectangle(img, (width//2+100, height//4+80), \n",
                "                  (width//2+180, height//2+50), (255, 200, 180), -1)\n",
                "    \n",
                "    # Legs\n",
                "    cv2.rectangle(img, (width//2-80, height//2+100), \n",
                "                  (width//2-20, height-100), (50, 50, 100), -1)\n",
                "    cv2.rectangle(img, (width//2+20, height//2+100), \n",
                "                  (width//2+80, height-100), (50, 50, 100), -1)\n",
                "    \n",
                "    return img\n",
                "\n",
                "def create_sample_garment_image(width=768, height=1024, color=None):\n",
                "    \"\"\"Create a sample garment (shirt) image\"\"\"\n",
                "    img = np.ones((height, width, 3), dtype=np.uint8) * 255\n",
                "    \n",
                "    if color is None:\n",
                "        color = (random.randint(50, 200), random.randint(50, 200), random.randint(50, 200))\n",
                "    \n",
                "    # Draw simple shirt shape\n",
                "    points = np.array([\n",
                "        [width//2-150, height//3],\n",
                "        [width//2-200, height//3+100],\n",
                "        [width//2-120, height//2+150],\n",
                "        [width//2+120, height//2+150],\n",
                "        [width//2+200, height//3+100],\n",
                "        [width//2+150, height//3],\n",
                "    ], np.int32)\n",
                "    \n",
                "    cv2.fillPoly(img, [points], color)\n",
                "    \n",
                "    return img\n",
                "\n",
                "def create_sample_segmentation_mask(width=768, height=1024):\n",
                "    \"\"\"Create a sample segmentation mask\"\"\"\n",
                "    mask = np.zeros((height, width), dtype=np.uint8)\n",
                "    \n",
                "    # Different regions with different labels\n",
                "    # 0: background, 5: upper-clothes, 13: face, 14-15: arms, 16-17: legs\n",
                "    \n",
                "    # Face (label 13)\n",
                "    cv2.circle(mask, (width//2, height//4), 80, 13, -1)\n",
                "    \n",
                "    # Upper clothes (label 5)\n",
                "    cv2.rectangle(mask, (width//2-100, height//4+50), \n",
                "                  (width//2+100, height//2+100), 5, -1)\n",
                "    \n",
                "    # Arms (labels 14, 15)\n",
                "    cv2.rectangle(mask, (width//2-180, height//4+80), \n",
                "                  (width//2-100, height//2+50), 14, -1)\n",
                "    cv2.rectangle(mask, (width//2+100, height//4+80), \n",
                "                  (width//2+180, height//2+50), 15, -1)\n",
                "    \n",
                "    # Legs (labels 16, 17)\n",
                "    cv2.rectangle(mask, (width//2-80, height//2+100), \n",
                "                  (width//2-20, height-100), 16, -1)\n",
                "    cv2.rectangle(mask, (width//2+20, height//2+100), \n",
                "                  (width//2+80, height-100), 17, -1)\n",
                "    \n",
                "    return mask\n",
                "\n",
                "print(\"‚úÖ Sample image generation functions created!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate sample dataset (10 samples for demonstration)\n",
                "num_samples = 10\n",
                "\n",
                "print(\"üé® Generating sample dataset...\\n\")\n",
                "\n",
                "train_dir = raw_data_dir / 'viton-hd' / 'train'\n",
                "pairs = []\n",
                "\n",
                "for i in tqdm(range(num_samples), desc=\"Creating samples\"):\n",
                "    # Generate IDs\n",
                "    person_id = f\"{i:05d}_00\"\n",
                "    cloth_id = f\"{i:05d}_00\"\n",
                "    \n",
                "    # Create person image\n",
                "    person_img = create_sample_person_image()\n",
                "    person_path = train_dir / 'image' / f\"{person_id}.jpg\"\n",
                "    cv2.imwrite(str(person_path), cv2.cvtColor(person_img, cv2.COLOR_RGB2BGR))\n",
                "    \n",
                "    # Create garment image\n",
                "    garment_img = create_sample_garment_image()\n",
                "    garment_path = train_dir / 'cloth' / f\"{cloth_id}.jpg\"\n",
                "    cv2.imwrite(str(garment_path), cv2.cvtColor(garment_img, cv2.COLOR_RGB2BGR))\n",
                "    \n",
                "    # Create segmentation mask\n",
                "    seg_mask = create_sample_segmentation_mask()\n",
                "    seg_path = train_dir / 'image-parse-v3' / f\"{person_id}.png\"\n",
                "    cv2.imwrite(str(seg_path), seg_mask)\n",
                "    \n",
                "    # Create pose keypoints (simplified JSON)\n",
                "    pose_data = {\n",
                "        \"version\": 1.3,\n",
                "        \"people\": [{\n",
                "            \"pose_keypoints_2d\": [384, 256, 0.9] * 18  # Simplified 18 keypoints\n",
                "        }]\n",
                "    }\n",
                "    pose_path = train_dir / 'openpose_json' / f\"{person_id}_keypoints.json\"\n",
                "    with open(pose_path, 'w') as f:\n",
                "        json.dump(pose_data, f)\n",
                "    \n",
                "    # Add to pairs\n",
                "    pairs.append(f\"{person_id}.jpg {cloth_id}.jpg\")\n",
                "\n",
                "# Save pairs file\n",
                "pairs_path = train_dir / 'train_pairs.txt'\n",
                "with open(pairs_path, 'w') as f:\n",
                "    f.write('\\n'.join(pairs))\n",
                "\n",
                "print(f\"\\n‚úÖ Generated {num_samples} sample image pairs!\")\n",
                "print(f\"üìç Location: {train_dir}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5Ô∏è‚É£ Explore Dataset Structure"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Analyze dataset structure\n",
                "def analyze_dataset_structure(dataset_path):\n",
                "    \"\"\"Analyze and display dataset structure\"\"\"\n",
                "    dataset_path = Path(dataset_path)\n",
                "    \n",
                "    if not dataset_path.exists():\n",
                "        print(f\"‚ùå Dataset not found at {dataset_path}\")\n",
                "        return\n",
                "    \n",
                "    print(\"=\"*70)\n",
                "    print(f\"üìä DATASET STRUCTURE ANALYSIS\")\n",
                "    print(\"=\"*70)\n",
                "    \n",
                "    for split in ['train', 'test']:\n",
                "        split_path = dataset_path / split\n",
                "        if not split_path.exists():\n",
                "            continue\n",
                "            \n",
                "        print(f\"\\nüìÅ {split.upper()} Split:\")\n",
                "        print(\"-\" * 50)\n",
                "        \n",
                "        for subdir in split_path.iterdir():\n",
                "            if subdir.is_dir():\n",
                "                num_files = len(list(subdir.glob('*')))\n",
                "                print(f\"   {subdir.name:20s} : {num_files:5d} files\")\n",
                "            elif subdir.is_file():\n",
                "                print(f\"   {subdir.name:20s} : file\")\n",
                "    \n",
                "    print(\"\\n\" + \"=\"*70)\n",
                "\n",
                "# Analyze VITON-HD dataset\n",
                "viton_hd_path = raw_data_dir / 'viton-hd'\n",
                "analyze_dataset_structure(viton_hd_path)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6Ô∏è‚É£ Load and Visualize Sample Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load pairs file\n",
                "pairs_file = raw_data_dir / 'viton-hd' / 'train' / 'train_pairs.txt'\n",
                "\n",
                "if pairs_file.exists():\n",
                "    with open(pairs_file, 'r') as f:\n",
                "        pairs_data = [line.strip().split() for line in f.readlines()]\n",
                "    \n",
                "    print(\"=\"*70)\n",
                "    print(\"üìã DATASET PAIRS INFORMATION\")\n",
                "    print(\"=\"*70)\n",
                "    print(f\"\\nTotal pairs: {len(pairs_data)}\")\n",
                "    print(f\"\\nFirst 5 pairs:\")\n",
                "    for i, (person, garment) in enumerate(pairs_data[:5]):\n",
                "        print(f\"   {i+1}. Person: {person:20s} | Garment: {garment}\")\n",
                "    print(\"\\n\" + \"=\"*70)\n",
                "else:\n",
                "    print(\"‚ö†Ô∏è  Pairs file not found. Please ensure dataset is downloaded.\")\n",
                "    pairs_data = []"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualization function\n",
                "def visualize_sample(person_img, garment_img, seg_mask, pose_img=None, title=\"Sample\"):\n",
                "    \"\"\"Visualize a complete sample with all components\"\"\"\n",
                "    \n",
                "    if pose_img is not None:\n",
                "        fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
                "    else:\n",
                "        fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
                "    \n",
                "    # Person image\n",
                "    axes[0].imshow(person_img)\n",
                "    axes[0].set_title('Person Image', fontsize=12, fontweight='bold')\n",
                "    axes[0].axis('off')\n",
                "    \n",
                "    # Garment image\n",
                "    axes[1].imshow(garment_img)\n",
                "    axes[1].set_title('Garment Image', fontsize=12, fontweight='bold')\n",
                "    axes[1].axis('off')\n",
                "    \n",
                "    # Segmentation mask\n",
                "    axes[2].imshow(seg_mask, cmap='tab20')\n",
                "    axes[2].set_title('Segmentation Mask', fontsize=12, fontweight='bold')\n",
                "    axes[2].axis('off')\n",
                "    \n",
                "    # Pose visualization (if available)\n",
                "    if pose_img is not None:\n",
                "        axes[3].imshow(pose_img)\n",
                "        axes[3].set_title('Pose Keypoints', fontsize=12, fontweight='bold')\n",
                "        axes[3].axis('off')\n",
                "    \n",
                "    plt.suptitle(title, fontsize=14, fontweight='bold', y=1.02)\n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "\n",
                "print(\"‚úÖ Visualization function created!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load and visualize random samples\n",
                "if pairs_data:\n",
                "    train_dir = raw_data_dir / 'viton-hd' / 'train'\n",
                "    \n",
                "    # Select random samples\n",
                "    num_visualize = min(3, len(pairs_data))\n",
                "    sample_indices = random.sample(range(len(pairs_data)), num_visualize)\n",
                "    \n",
                "    print(\"=\"*70)\n",
                "    print(\"üé® VISUALIZING SAMPLE DATA\")\n",
                "    print(\"=\"*70)\n",
                "    \n",
                "    for idx in sample_indices:\n",
                "        person_name, garment_name = pairs_data[idx]\n",
                "        \n",
                "        # Load images\n",
                "        person_path = train_dir / 'image' / person_name\n",
                "        garment_path = train_dir / 'cloth' / garment_name\n",
                "        seg_path = train_dir / 'image-parse-v3' / person_name.replace('.jpg', '.png')\n",
                "        \n",
                "        if person_path.exists() and garment_path.exists() and seg_path.exists():\n",
                "            person_img = cv2.imread(str(person_path))\n",
                "            person_img = cv2.cvtColor(person_img, cv2.COLOR_BGR2RGB)\n",
                "            \n",
                "            garment_img = cv2.imread(str(garment_path))\n",
                "            garment_img = cv2.cvtColor(garment_img, cv2.COLOR_BGR2RGB)\n",
                "            \n",
                "            seg_mask = cv2.imread(str(seg_path), cv2.IMREAD_GRAYSCALE)\n",
                "            \n",
                "            # Visualize\n",
                "            visualize_sample(\n",
                "                person_img, garment_img, seg_mask,\n",
                "                title=f\"Sample {idx+1}: {person_name} + {garment_name}\"\n",
                "            )\n",
                "        else:\n",
                "            print(f\"‚ö†Ô∏è  Sample {idx+1} files not found\")\n",
                "else:\n",
                "    print(\"‚ö†Ô∏è  No pairs data available for visualization\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7Ô∏è‚É£ Image Statistics and Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Analyze image dimensions and statistics\n",
                "def analyze_image_statistics(image_dir, num_samples=50):\n",
                "    \"\"\"Analyze image dimensions and basic statistics\"\"\"\n",
                "    image_dir = Path(image_dir)\n",
                "    \n",
                "    if not image_dir.exists():\n",
                "        print(f\"‚ùå Directory not found: {image_dir}\")\n",
                "        return\n",
                "    \n",
                "    image_files = list(image_dir.glob('*.jpg')) + list(image_dir.glob('*.png'))\n",
                "    \n",
                "    if not image_files:\n",
                "        print(f\"‚ùå No images found in {image_dir}\")\n",
                "        return\n",
                "    \n",
                "    # Sample images for analysis\n",
                "    sample_files = random.sample(image_files, min(num_samples, len(image_files)))\n",
                "    \n",
                "    dimensions = []\n",
                "    file_sizes = []\n",
                "    \n",
                "    for img_path in tqdm(sample_files, desc=\"Analyzing images\"):\n",
                "        img = Image.open(img_path)\n",
                "        dimensions.append(img.size)  # (width, height)\n",
                "        file_sizes.append(img_path.stat().st_size / 1024)  # KB\n",
                "    \n",
                "    # Convert to DataFrame for analysis\n",
                "    df = pd.DataFrame({\n",
                "        'width': [d[0] for d in dimensions],\n",
                "        'height': [d[1] for d in dimensions],\n",
                "        'file_size_kb': file_sizes\n",
                "    })\n",
                "    \n",
                "    return df\n",
                "\n",
                "# Analyze person images\n",
                "person_dir = raw_data_dir / 'viton-hd' / 'train' / 'image'\n",
                "if person_dir.exists():\n",
                "    print(\"üìä Analyzing person images...\\n\")\n",
                "    person_stats = analyze_image_statistics(person_dir)\n",
                "    \n",
                "    if person_stats is not None:\n",
                "        print(\"=\"*70)\n",
                "        print(\"üìà PERSON IMAGES STATISTICS\")\n",
                "        print(\"=\"*70)\n",
                "        print(person_stats.describe())\n",
                "        print(\"\\n\" + \"=\"*70)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize dimension distribution\n",
                "if person_stats is not None and len(person_stats) > 0:\n",
                "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
                "    \n",
                "    # Width distribution\n",
                "    axes[0].hist(person_stats['width'], bins=20, color='skyblue', edgecolor='black')\n",
                "    axes[0].set_title('Image Width Distribution', fontweight='bold')\n",
                "    axes[0].set_xlabel('Width (pixels)')\n",
                "    axes[0].set_ylabel('Frequency')\n",
                "    axes[0].grid(True, alpha=0.3)\n",
                "    \n",
                "    # Height distribution\n",
                "    axes[1].hist(person_stats['height'], bins=20, color='lightcoral', edgecolor='black')\n",
                "    axes[1].set_title('Image Height Distribution', fontweight='bold')\n",
                "    axes[1].set_xlabel('Height (pixels)')\n",
                "    axes[1].set_ylabel('Frequency')\n",
                "    axes[1].grid(True, alpha=0.3)\n",
                "    \n",
                "    # File size distribution\n",
                "    axes[2].hist(person_stats['file_size_kb'], bins=20, color='lightgreen', edgecolor='black')\n",
                "    axes[2].set_title('File Size Distribution', fontweight='bold')\n",
                "    axes[2].set_xlabel('File Size (KB)')\n",
                "    axes[2].set_ylabel('Frequency')\n",
                "    axes[2].grid(True, alpha=0.3)\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8Ô∏è‚É£ Segmentation Mask Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define segmentation labels (VITON-HD uses 20 classes)\n",
                "SEGMENTATION_LABELS = {\n",
                "    0: 'background',\n",
                "    1: 'hat',\n",
                "    2: 'hair',\n",
                "    3: 'glove',\n",
                "    4: 'sunglasses',\n",
                "    5: 'upper-clothes',\n",
                "    6: 'dress',\n",
                "    7: 'coat',\n",
                "    8: 'socks',\n",
                "    9: 'pants',\n",
                "    10: 'jumpsuits',\n",
                "    11: 'scarf',\n",
                "    12: 'skirt',\n",
                "    13: 'face',\n",
                "    14: 'left-arm',\n",
                "    15: 'right-arm',\n",
                "    16: 'left-leg',\n",
                "    17: 'right-leg',\n",
                "    18: 'left-shoe',\n",
                "    19: 'right-shoe'\n",
                "}\n",
                "\n",
                "print(\"üìã Segmentation Labels:\")\n",
                "print(\"=\"*70)\n",
                "for label_id, label_name in SEGMENTATION_LABELS.items():\n",
                "    print(f\"   {label_id:2d}: {label_name}\")\n",
                "print(\"=\"*70)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Analyze segmentation masks\n",
                "def analyze_segmentation_masks(mask_dir, num_samples=20):\n",
                "    \"\"\"Analyze segmentation mask label distribution\"\"\"\n",
                "    mask_dir = Path(mask_dir)\n",
                "    \n",
                "    if not mask_dir.exists():\n",
                "        print(f\"‚ùå Mask directory not found: {mask_dir}\")\n",
                "        return None\n",
                "    \n",
                "    mask_files = list(mask_dir.glob('*.png'))\n",
                "    \n",
                "    if not mask_files:\n",
                "        print(f\"‚ùå No mask files found in {mask_dir}\")\n",
                "        return None\n",
                "    \n",
                "    sample_files = random.sample(mask_files, min(num_samples, len(mask_files)))\n",
                "    \n",
                "    label_counts = Counter()\n",
                "    \n",
                "    for mask_path in tqdm(sample_files, desc=\"Analyzing masks\"):\n",
                "        mask = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)\n",
                "        unique_labels, counts = np.unique(mask, return_counts=True)\n",
                "        \n",
                "        for label, count in zip(unique_labels, counts):\n",
                "            label_counts[label] += count\n",
                "    \n",
                "    return label_counts\n",
                "\n",
                "# Analyze masks\n",
                "mask_dir = raw_data_dir / 'viton-hd' / 'train' / 'image-parse-v3'\n",
                "if mask_dir.exists():\n",
                "    print(\"üé≠ Analyzing segmentation masks...\\n\")\n",
                "    label_distribution = analyze_segmentation_masks(mask_dir)\n",
                "    \n",
                "    if label_distribution:\n",
                "        print(\"\\n\" + \"=\"*70)\n",
                "        print(\"üìä LABEL DISTRIBUTION\")\n",
                "        print(\"=\"*70)\n",
                "        \n",
                "        for label_id in sorted(label_distribution.keys()):\n",
                "            label_name = SEGMENTATION_LABELS.get(label_id, 'unknown')\n",
                "            count = label_distribution[label_id]\n",
                "            print(f\"   {label_id:2d} ({label_name:15s}): {count:12,d} pixels\")\n",
                "        \n",
                "        print(\"=\"*70)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize label distribution\n",
                "if label_distribution:\n",
                "    labels = [SEGMENTATION_LABELS.get(k, f'Label {k}') for k in sorted(label_distribution.keys())]\n",
                "    counts = [label_distribution[k] for k in sorted(label_distribution.keys())]\n",
                "    \n",
                "    plt.figure(figsize=(14, 6))\n",
                "    bars = plt.bar(range(len(labels)), counts, color='steelblue', edgecolor='black')\n",
                "    plt.xticks(range(len(labels)), labels, rotation=45, ha='right')\n",
                "    plt.xlabel('Segmentation Labels', fontweight='bold')\n",
                "    plt.ylabel('Pixel Count', fontweight='bold')\n",
                "    plt.title('Segmentation Label Distribution', fontsize=14, fontweight='bold')\n",
                "    plt.yscale('log')  # Log scale for better visualization\n",
                "    plt.grid(True, alpha=0.3, axis='y')\n",
                "    plt.tight_layout()\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9Ô∏è‚É£ Pose Keypoints Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load and analyze pose keypoints\n",
                "def load_pose_keypoints(json_path):\n",
                "    \"\"\"Load pose keypoints from OpenPose JSON file\"\"\"\n",
                "    with open(json_path, 'r') as f:\n",
                "        data = json.load(f)\n",
                "    \n",
                "    if 'people' in data and len(data['people']) > 0:\n",
                "        keypoints = data['people'][0]['pose_keypoints_2d']\n",
                "        # Reshape to (18, 3) - 18 keypoints with (x, y, confidence)\n",
                "        keypoints = np.array(keypoints).reshape(-1, 3)\n",
                "        return keypoints\n",
                "    \n",
                "    return None\n",
                "\n",
                "# OpenPose keypoint names\n",
                "POSE_KEYPOINT_NAMES = [\n",
                "    'Nose', 'Neck', 'RShoulder', 'RElbow', 'RWrist',\n",
                "    'LShoulder', 'LElbow', 'LWrist', 'MidHip', 'RHip',\n",
                "    'RKnee', 'RAnkle', 'LHip', 'LKnee', 'LAnkle',\n",
                "    'REye', 'LEye', 'REar', 'LEar'\n",
                "]\n",
                "\n",
                "print(\"üìç OpenPose Keypoints:\")\n",
                "print(\"=\"*70)\n",
                "for i, name in enumerate(POSE_KEYPOINT_NAMES[:18]):\n",
                "    print(f\"   {i:2d}: {name}\")\n",
                "print(\"=\"*70)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize pose keypoints on image\n",
                "def visualize_pose_keypoints(image, keypoints):\n",
                "    \"\"\"Visualize pose keypoints on image\"\"\"\n",
                "    img_copy = image.copy()\n",
                "    \n",
                "    # Draw keypoints\n",
                "    for i, (x, y, conf) in enumerate(keypoints):\n",
                "        if conf > 0.1:  # Only draw if confidence > threshold\n",
                "            cv2.circle(img_copy, (int(x), int(y)), 5, (0, 255, 0), -1)\n",
                "            cv2.putText(img_copy, str(i), (int(x)+10, int(y)), \n",
                "                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)\n",
                "    \n",
                "    # Draw skeleton connections\n",
                "    skeleton = [\n",
                "        (0, 1), (1, 2), (2, 3), (3, 4),  # Right arm\n",
                "        (1, 5), (5, 6), (6, 7),  # Left arm\n",
                "        (1, 8), (8, 9), (9, 10), (10, 11),  # Right leg\n",
                "        (8, 12), (12, 13), (13, 14),  # Left leg\n",
                "        (0, 15), (0, 16), (15, 17), (16, 18)  # Face\n",
                "    ]\n",
                "    \n",
                "    for start_idx, end_idx in skeleton:\n",
                "        if start_idx < len(keypoints) and end_idx < len(keypoints):\n",
                "            start_point = keypoints[start_idx]\n",
                "            end_point = keypoints[end_idx]\n",
                "            \n",
                "            if start_point[2] > 0.1 and end_point[2] > 0.1:\n",
                "                cv2.line(img_copy, \n",
                "                        (int(start_point[0]), int(start_point[1])),\n",
                "                        (int(end_point[0]), int(end_point[1])),\n",
                "                        (255, 0, 0), 2)\n",
                "    \n",
                "    return img_copy\n",
                "\n",
                "print(\"‚úÖ Pose visualization function created!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load and visualize a sample with pose\n",
                "if pairs_data:\n",
                "    train_dir = raw_data_dir / 'viton-hd' / 'train'\n",
                "    \n",
                "    # Get first sample\n",
                "    person_name, _ = pairs_data[0]\n",
                "    \n",
                "    person_path = train_dir / 'image' / person_name\n",
                "    pose_json_path = train_dir / 'openpose_json' / person_name.replace('.jpg', '_keypoints.json')\n",
                "    \n",
                "    if person_path.exists() and pose_json_path.exists():\n",
                "        # Load image\n",
                "        person_img = cv2.imread(str(person_path))\n",
                "        person_img = cv2.cvtColor(person_img, cv2.COLOR_BGR2RGB)\n",
                "        \n",
                "        # Load keypoints\n",
                "        keypoints = load_pose_keypoints(pose_json_path)\n",
                "        \n",
                "        if keypoints is not None:\n",
                "            # Visualize\n",
                "            pose_vis = visualize_pose_keypoints(person_img, keypoints)\n",
                "            \n",
                "            fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
                "            \n",
                "            axes[0].imshow(person_img)\n",
                "            axes[0].set_title('Original Image', fontweight='bold')\n",
                "            axes[0].axis('off')\n",
                "            \n",
                "            axes[1].imshow(pose_vis)\n",
                "            axes[1].set_title('Pose Keypoints Visualization', fontweight='bold')\n",
                "            axes[1].axis('off')\n",
                "            \n",
                "            plt.suptitle('Pose Estimation Example', fontsize=14, fontweight='bold')\n",
                "            plt.tight_layout()\n",
                "            plt.show()\n",
                "            \n",
                "            print(\"\\nüìä Keypoint Confidence Scores:\")\n",
                "            print(\"=\"*70)\n",
                "            for i, (x, y, conf) in enumerate(keypoints[:18]):\n",
                "                print(f\"   {POSE_KEYPOINT_NAMES[i]:15s}: ({x:6.1f}, {y:6.1f}) - Confidence: {conf:.3f}\")\n",
                "            print(\"=\"*70)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üîü Data Quality Check"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check for missing or corrupted files\n",
                "def check_data_quality(dataset_path, pairs_file):\n",
                "    \"\"\"Check for missing or corrupted files in dataset\"\"\"\n",
                "    dataset_path = Path(dataset_path)\n",
                "    \n",
                "    # Load pairs\n",
                "    with open(pairs_file, 'r') as f:\n",
                "        pairs = [line.strip().split() for line in f.readlines()]\n",
                "    \n",
                "    print(\"=\"*70)\n",
                "    print(\"üîç DATA QUALITY CHECK\")\n",
                "    print(\"=\"*70)\n",
                "    print(f\"\\nChecking {len(pairs)} pairs...\\n\")\n",
                "    \n",
                "    missing_files = []\n",
                "    corrupted_files = []\n",
                "    \n",
                "    for person_name, garment_name in tqdm(pairs, desc=\"Checking files\"):\n",
                "        # Check person image\n",
                "        person_path = dataset_path / 'image' / person_name\n",
                "        if not person_path.exists():\n",
                "            missing_files.append(('person', person_name))\n",
                "        else:\n",
                "            try:\n",
                "                img = Image.open(person_path)\n",
                "                img.verify()\n",
                "            except:\n",
                "                corrupted_files.append(('person', person_name))\n",
                "        \n",
                "        # Check garment image\n",
                "        garment_path = dataset_path / 'cloth' / garment_name\n",
                "        if not garment_path.exists():\n",
                "            missing_files.append(('garment', garment_name))\n",
                "        else:\n",
                "            try:\n",
                "                img = Image.open(garment_path)\n",
                "                img.verify()\n",
                "            except:\n",
                "                corrupted_files.append(('garment', garment_name))\n",
                "        \n",
                "        # Check segmentation mask\n",
                "        seg_path = dataset_path / 'image-parse-v3' / person_name.replace('.jpg', '.png')\n",
                "        if not seg_path.exists():\n",
                "            missing_files.append(('segmentation', person_name))\n",
                "    \n",
                "    # Report results\n",
                "    print(\"\\n\" + \"=\"*70)\n",
                "    print(\"üìä QUALITY CHECK RESULTS\")\n",
                "    print(\"=\"*70)\n",
                "    print(f\"\\nTotal pairs checked: {len(pairs)}\")\n",
                "    print(f\"Missing files: {len(missing_files)}\")\n",
                "    print(f\"Corrupted files: {len(corrupted_files)}\")\n",
                "    \n",
                "    if missing_files:\n",
                "        print(f\"\\n‚ö†Ô∏è  First 5 missing files:\")\n",
                "        for file_type, filename in missing_files[:5]:\n",
                "            print(f\"   - {file_type}: {filename}\")\n",
                "    \n",
                "    if corrupted_files:\n",
                "        print(f\"\\n‚ö†Ô∏è  First 5 corrupted files:\")\n",
                "        for file_type, filename in corrupted_files[:5]:\n",
                "            print(f\"   - {file_type}: {filename}\")\n",
                "    \n",
                "    if not missing_files and not corrupted_files:\n",
                "        print(\"\\n‚úÖ All files are present and valid!\")\n",
                "    \n",
                "    print(\"\\n\" + \"=\"*70)\n",
                "    \n",
                "    return missing_files, corrupted_files\n",
                "\n",
                "# Run quality check\n",
                "train_dir = raw_data_dir / 'viton-hd' / 'train'\n",
                "pairs_file = train_dir / 'train_pairs.txt'\n",
                "\n",
                "if train_dir.exists() and pairs_file.exists():\n",
                "    missing, corrupted = check_data_quality(train_dir, pairs_file)\n",
                "else:\n",
                "    print(\"‚ö†Ô∏è  Dataset or pairs file not found\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1Ô∏è‚É£1Ô∏è‚É£ Summary Statistics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create comprehensive summary\n",
                "print(\"=\"*70)\n",
                "print(\"üìä DATASET SUMMARY\")\n",
                "print(\"=\"*70)\n",
                "\n",
                "summary = {\n",
                "    'Dataset': 'VITON-HD (Sample)',\n",
                "    'Total Pairs': len(pairs_data) if pairs_data else 0,\n",
                "    'Image Resolution': '768 x 1024 pixels',\n",
                "    'Segmentation Classes': 20,\n",
                "    'Pose Keypoints': 18,\n",
                "    'Data Quality': '‚úÖ Good' if not (missing or corrupted) else '‚ö†Ô∏è  Issues Found'\n",
                "}\n",
                "\n",
                "for key, value in summary.items():\n",
                "    print(f\"\\n{key:25s}: {value}\")\n",
                "\n",
                "print(\"\\n\" + \"=\"*70)\n",
                "print(\"\\n‚úÖ Data exploration complete!\")\n",
                "print(\"\\nüöÄ Next Steps:\")\n",
                "print(\"   1. Download full VITON-HD dataset if needed\")\n",
                "print(\"   2. Proceed to notebook 03_data_preprocessing.ipynb\")\n",
                "print(\"   3. Preprocess images and create training dataset\")\n",
                "print(\"\\n\" + \"=\"*70)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## üìù Key Takeaways\n",
                "\n",
                "### What We Learned:\n",
                "\n",
                "1. **Dataset Structure**\n",
                "   - VITON-HD contains person-garment pairs with rich annotations\n",
                "   - Each sample includes: image, garment, segmentation mask, and pose keypoints\n",
                "   - Standard resolution: 768√ó1024 pixels\n",
                "\n",
                "2. **Segmentation Masks**\n",
                "   - 20 semantic classes covering body parts and clothing\n",
                "   - Critical for garment region identification\n",
                "   - Used for warping and blending operations\n",
                "\n",
                "3. **Pose Keypoints**\n",
                "   - 18 body keypoints from OpenPose\n",
                "   - Essential for pose-guided generation\n",
                "   - Used in ControlNet conditioning\n",
                "\n",
                "4. **Data Quality**\n",
                "   - Important to check for missing/corrupted files\n",
                "   - Consistent image dimensions across dataset\n",
                "   - Clean annotations for better training\n",
                "\n",
                "### Important Notes:\n",
                "\n",
                "- **Full Dataset**: Download complete VITON-HD (~15GB) for production training\n",
                "- **Storage**: Ensure sufficient disk space (50GB+ recommended)\n",
                "- **Preprocessing**: Next notebook will handle image preprocessing and augmentation\n",
                "- **Custom Data**: You can add your own e-commerce images following the same structure\n",
                "\n",
                "---\n",
                "\n",
                "## üîó Resources\n",
                "\n",
                "- [VITON-HD Paper](https://arxiv.org/abs/2103.16874)\n",
                "- [VITON-HD GitHub](https://github.com/shadow2496/VITON-HD)\n",
                "- [OpenPose](https://github.com/CMU-Perceptual-Computing-Lab/openpose)\n",
                "- [Graphonomy (Human Parsing)](https://github.com/Gaoyiminggithub/Graphonomy)\n",
                "\n",
                "---\n",
                "\n",
                "**Author**: Huzaifa Nasir  \n",
                "**Date**: December 2025  \n",
                "**Notebook**: 02_data_exploration.ipynb  \n",
                "**Status**: ‚úÖ Complete"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}