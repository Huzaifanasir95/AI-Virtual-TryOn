{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93b38e40",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ff9a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from collections import Counter, defaultdict\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e7291b",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Setup Project Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dadfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get project root directory\n",
    "project_root = Path.cwd().parent\n",
    "print(f\"üìÅ Project Root: {project_root}\")\n",
    "\n",
    "# Dataset path\n",
    "dataset_root = project_root / 'data' / 'zalando-hd-resized'\n",
    "print(f\"üìÅ Dataset Root: {dataset_root}\")\n",
    "\n",
    "# Check if dataset exists\n",
    "if not dataset_root.exists():\n",
    "    print(\"\\n‚ùå ERROR: Dataset not found!\")\n",
    "    print(f\"Expected location: {dataset_root}\")\n",
    "    print(\"\\nPlease ensure the dataset is placed in the correct location.\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ Dataset found!\")\n",
    "    print(f\"\\nüìÇ Dataset contents:\")\n",
    "    for item in sorted(dataset_root.iterdir()):\n",
    "        print(f\"   - {item.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2127121a",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Explore Dataset Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2762a2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_directory_structure(root_path, max_depth=3, current_depth=0, prefix=\"\"):\n",
    "    \"\"\"Recursively explore directory structure\"\"\"\n",
    "    if current_depth >= max_depth:\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        items = sorted(root_path.iterdir())\n",
    "        for i, item in enumerate(items):\n",
    "            is_last = i == len(items) - 1\n",
    "            current_prefix = \"‚îî‚îÄ‚îÄ \" if is_last else \"‚îú‚îÄ‚îÄ \"\n",
    "            \n",
    "            if item.is_dir():\n",
    "                # Count files in directory\n",
    "                try:\n",
    "                    file_count = len(list(item.glob('*')))\n",
    "                    print(f\"{prefix}{current_prefix}üìÅ {item.name}/ ({file_count} items)\")\n",
    "                except:\n",
    "                    print(f\"{prefix}{current_prefix}üìÅ {item.name}/\")\n",
    "                \n",
    "                # Recurse into subdirectory\n",
    "                next_prefix = prefix + (\"    \" if is_last else \"‚îÇ   \")\n",
    "                explore_directory_structure(item, max_depth, current_depth + 1, next_prefix)\n",
    "            else:\n",
    "                # Show file with size\n",
    "                size_mb = item.stat().st_size / (1024 * 1024)\n",
    "                if size_mb > 1:\n",
    "                    print(f\"{prefix}{current_prefix}üìÑ {item.name} ({size_mb:.2f} MB)\")\n",
    "                else:\n",
    "                    print(f\"{prefix}{current_prefix}üìÑ {item.name}\")\n",
    "    except PermissionError:\n",
    "        print(f\"{prefix}‚ùå Permission denied\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üìÇ DATASET STRUCTURE\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "explore_directory_structure(dataset_root, max_depth=3)\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964c421a",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Identify Train and Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a935d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find train and test directories\n",
    "train_dir = dataset_root / 'train'\n",
    "test_dir = dataset_root / 'test'\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üìä DATASET SPLITS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "splits_found = []\n",
    "\n",
    "if train_dir.exists():\n",
    "    print(f\"\\n‚úÖ Train Split Found: {train_dir}\")\n",
    "    splits_found.append(('train', train_dir))\n",
    "else:\n",
    "    print(f\"\\n‚ùå Train Split NOT Found: {train_dir}\")\n",
    "\n",
    "if test_dir.exists():\n",
    "    print(f\"‚úÖ Test Split Found: {test_dir}\")\n",
    "    splits_found.append(('test', test_dir))\n",
    "else:\n",
    "    print(f\"‚ùå Test Split NOT Found: {test_dir}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "\n",
    "# Store for later use\n",
    "if not splits_found:\n",
    "    print(\"\\n‚ö†Ô∏è  Warning: No standard train/test splits found.\")\n",
    "    print(\"Exploring root directory for data...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f21983",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Analyze Data Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6f8a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_files_by_extension(directory):\n",
    "    \"\"\"Count files grouped by extension\"\"\"\n",
    "    extensions = defaultdict(int)\n",
    "    total_size = 0\n",
    "    \n",
    "    for file in directory.rglob('*'):\n",
    "        if file.is_file():\n",
    "            ext = file.suffix.lower() or 'no_extension'\n",
    "            extensions[ext] += 1\n",
    "            total_size += file.stat().st_size\n",
    "    \n",
    "    return dict(extensions), total_size\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üìä DATA COMPONENT ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "dataset_stats = {}\n",
    "\n",
    "for split_name, split_path in splits_found:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"üìÅ {split_name.upper()} SPLIT\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Check for standard VITON-HD components\n",
    "    components = {\n",
    "        'image': split_path / 'image',\n",
    "        'cloth': split_path / 'cloth',\n",
    "        'image-parse-v3': split_path / 'image-parse-v3',\n",
    "        'openpose_img': split_path / 'openpose_img',\n",
    "        'openpose_json': split_path / 'openpose_json',\n",
    "    }\n",
    "    \n",
    "    split_stats = {}\n",
    "    \n",
    "    for component_name, component_path in components.items():\n",
    "        if component_path.exists():\n",
    "            file_count = len(list(component_path.glob('*')))\n",
    "            extensions, total_size = count_files_by_extension(component_path)\n",
    "            \n",
    "            split_stats[component_name] = {\n",
    "                'count': file_count,\n",
    "                'extensions': extensions,\n",
    "                'size_mb': total_size / (1024 * 1024)\n",
    "            }\n",
    "            \n",
    "            print(f\"\\n‚úÖ {component_name:20s}: {file_count:5d} files ({total_size/(1024*1024):.2f} MB)\")\n",
    "            for ext, count in sorted(extensions.items()):\n",
    "                print(f\"   - {ext:15s}: {count:5d} files\")\n",
    "        else:\n",
    "            print(f\"\\n‚ùå {component_name:20s}: NOT FOUND\")\n",
    "            split_stats[component_name] = {'count': 0, 'extensions': {}, 'size_mb': 0}\n",
    "    \n",
    "    dataset_stats[split_name] = split_stats\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e577bda1",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Create Summary Statistics Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf3c286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary DataFrame\n",
    "summary_data = []\n",
    "\n",
    "for split_name, split_stats in dataset_stats.items():\n",
    "    for component_name, stats in split_stats.items():\n",
    "        summary_data.append({\n",
    "            'Split': split_name.capitalize(),\n",
    "            'Component': component_name,\n",
    "            'File Count': stats['count'],\n",
    "            'Size (MB)': f\"{stats['size_mb']:.2f}\",\n",
    "            'Extensions': ', '.join(stats['extensions'].keys()) if stats['extensions'] else 'N/A'\n",
    "        })\n",
    "\n",
    "df_summary = pd.DataFrame(summary_data)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üìã DATASET SUMMARY TABLE\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "print(df_summary.to_string(index=False))\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "\n",
    "# Calculate totals\n",
    "total_files = df_summary['File Count'].sum()\n",
    "total_size = df_summary['Size (MB)'].apply(lambda x: float(x)).sum()\n",
    "\n",
    "print(f\"\\nüìä Total Files: {total_files:,}\")\n",
    "print(f\"üìä Total Size: {total_size:.2f} MB ({total_size/1024:.2f} GB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30595c18",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Visualize Dataset Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d778de69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot 1: File counts by component\n",
    "if not df_summary.empty:\n",
    "    df_pivot = df_summary.pivot(index='Component', columns='Split', values='File Count')\n",
    "    df_pivot.plot(kind='bar', ax=axes[0], color=['#3498db', '#e74c3c'])\n",
    "    axes[0].set_title('File Counts by Component and Split', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Component', fontsize=12)\n",
    "    axes[0].set_ylabel('Number of Files', fontsize=12)\n",
    "    axes[0].legend(title='Split', fontsize=10)\n",
    "    axes[0].tick_params(axis='x', rotation=45)\n",
    "    axes[0].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Size distribution\n",
    "    df_summary_copy = df_summary.copy()\n",
    "    df_summary_copy['Size (MB)'] = df_summary_copy['Size (MB)'].astype(float)\n",
    "    df_pivot_size = df_summary_copy.pivot(index='Component', columns='Split', values='Size (MB)')\n",
    "    df_pivot_size.plot(kind='bar', ax=axes[1], color=['#9b59b6', '#f39c12'])\n",
    "    axes[1].set_title('Storage Size by Component and Split', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Component', fontsize=12)\n",
    "    axes[1].set_ylabel('Size (MB)', fontsize=12)\n",
    "    axes[1].legend(title='Split', fontsize=10)\n",
    "    axes[1].tick_params(axis='x', rotation=45)\n",
    "    axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Dataset distribution visualized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f10098",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Load Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba3ad6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_samples(directory, n=5, extensions=['.jpg', '.png']):\n",
    "    \"\"\"Get random sample files from directory\"\"\"\n",
    "    all_files = []\n",
    "    for ext in extensions:\n",
    "        all_files.extend(list(directory.glob(f'*{ext}')))\n",
    "    \n",
    "    if not all_files:\n",
    "        return []\n",
    "    \n",
    "    n = min(n, len(all_files))\n",
    "    return np.random.choice(all_files, size=n, replace=False)\n",
    "\n",
    "# Get sample paths from train split (use first available split if train not found)\n",
    "sample_split = 'train' if train_dir.exists() else ('test' if test_dir.exists() else None)\n",
    "\n",
    "if sample_split:\n",
    "    split_path = train_dir if sample_split == 'train' else test_dir\n",
    "    \n",
    "    # Get sample images\n",
    "    person_images = get_random_samples(split_path / 'image', n=5)\n",
    "    cloth_images = get_random_samples(split_path / 'cloth', n=5)\n",
    "    parse_images = get_random_samples(split_path / 'image-parse-v3', n=5) if (split_path / 'image-parse-v3').exists() else []\n",
    "    pose_images = get_random_samples(split_path / 'openpose_img', n=5) if (split_path / 'openpose_img').exists() else []\n",
    "    \n",
    "    print(f\"‚úÖ Loaded {len(person_images)} person images\")\n",
    "    print(f\"‚úÖ Loaded {len(cloth_images)} cloth images\")\n",
    "    print(f\"‚úÖ Loaded {len(parse_images)} parsing masks\")\n",
    "    print(f\"‚úÖ Loaded {len(pose_images)} pose visualizations\")\n",
    "else:\n",
    "    print(\"‚ùå No data splits found for sampling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b04664",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Visualize Sample Person Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588b80c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if person_images:\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(20, 5))\n",
    "    fig.suptitle('Sample Person Images', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    for idx, img_path in enumerate(person_images):\n",
    "        img = Image.open(img_path)\n",
    "        axes[idx].imshow(img)\n",
    "        axes[idx].set_title(f\"{img_path.stem}\\n{img.size[0]}x{img.size[1]}\", fontsize=10)\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ùå No person images found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b22cab",
   "metadata": {},
   "source": [
    "## üîü Visualize Sample Garment Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae58a58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if cloth_images:\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(20, 5))\n",
    "    fig.suptitle('Sample Garment Images', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    for idx, img_path in enumerate(cloth_images):\n",
    "        img = Image.open(img_path)\n",
    "        axes[idx].imshow(img)\n",
    "        axes[idx].set_title(f\"{img_path.stem}\\n{img.size[0]}x{img.size[1]}\", fontsize=10)\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ùå No garment images found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730fcae1",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£1Ô∏è‚É£ Visualize Segmentation Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9da1dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if parse_images:\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(20, 5))\n",
    "    fig.suptitle('Sample Segmentation Masks (Human Parsing)', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    for idx, img_path in enumerate(parse_images):\n",
    "        img = Image.open(img_path)\n",
    "        axes[idx].imshow(img)\n",
    "        axes[idx].set_title(f\"{img_path.stem}\\n{img.size[0]}x{img.size[1]}\", fontsize=10)\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ùå No segmentation masks found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef8cd6f",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£2Ô∏è‚É£ Visualize Pose Estimations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f46f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pose_images:\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(20, 5))\n",
    "    fig.suptitle('Sample Pose Visualizations (OpenPose)', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    for idx, img_path in enumerate(pose_images):\n",
    "        img = Image.open(img_path)\n",
    "        axes[idx].imshow(img)\n",
    "        axes[idx].set_title(f\"{img_path.stem}\\n{img.size[0]}x{img.size[1]}\", fontsize=10)\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ùå No pose visualizations found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c268f75a",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£3Ô∏è‚É£ Analyze Image Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56522d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_image_dimensions(directory, sample_size=100):\n",
    "    \"\"\"Analyze dimensions of images in directory\"\"\"\n",
    "    image_files = list(directory.glob('*.jpg')) + list(directory.glob('*.png'))\n",
    "    \n",
    "    if not image_files:\n",
    "        return None\n",
    "    \n",
    "    # Sample if too many files\n",
    "    if len(image_files) > sample_size:\n",
    "        image_files = np.random.choice(image_files, size=sample_size, replace=False)\n",
    "    \n",
    "    dimensions = []\n",
    "    for img_path in image_files:\n",
    "        try:\n",
    "            img = Image.open(img_path)\n",
    "            dimensions.append(img.size)  # (width, height)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    return dimensions\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üìê IMAGE DIMENSION ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if sample_split:\n",
    "    split_path = train_dir if sample_split == 'train' else test_dir\n",
    "    \n",
    "    components_to_analyze = [\n",
    "        ('Person Images', split_path / 'image'),\n",
    "        ('Garment Images', split_path / 'cloth'),\n",
    "        ('Parsing Masks', split_path / 'image-parse-v3'),\n",
    "        ('Pose Images', split_path / 'openpose_img'),\n",
    "    ]\n",
    "    \n",
    "    dimension_stats = {}\n",
    "    \n",
    "    for component_name, component_path in components_to_analyze:\n",
    "        if component_path.exists():\n",
    "            print(f\"\\nüîç Analyzing {component_name}...\")\n",
    "            dims = analyze_image_dimensions(component_path, sample_size=100)\n",
    "            \n",
    "            if dims:\n",
    "                widths = [d[0] for d in dims]\n",
    "                heights = [d[1] for d in dims]\n",
    "                \n",
    "                dimension_stats[component_name] = {\n",
    "                    'dims': dims,\n",
    "                    'widths': widths,\n",
    "                    'heights': heights\n",
    "                }\n",
    "                \n",
    "                print(f\"   Samples analyzed: {len(dims)}\")\n",
    "                print(f\"   Width:  Min={min(widths):4d}, Max={max(widths):4d}, Mean={np.mean(widths):6.1f}\")\n",
    "                print(f\"   Height: Min={min(heights):4d}, Max={max(heights):4d}, Mean={np.mean(heights):6.1f}\")\n",
    "                \n",
    "                # Check for consistency\n",
    "                unique_dims = set(dims)\n",
    "                if len(unique_dims) == 1:\n",
    "                    print(f\"   ‚úÖ All images have consistent dimensions: {dims[0]}\")\n",
    "                else:\n",
    "                    print(f\"   ‚ö†Ô∏è  Found {len(unique_dims)} different dimensions\")\n",
    "                    print(f\"   Most common: {Counter(dims).most_common(3)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98370f2",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£4Ô∏è‚É£ Visualize Dimension Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fc5b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dimension_stats:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('Image Dimension Distributions', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    for idx, (component_name, stats) in enumerate(dimension_stats.items()):\n",
    "        if idx >= 4:  # Only plot first 4 components\n",
    "            break\n",
    "        \n",
    "        row = idx // 2\n",
    "        col = idx % 2\n",
    "        ax = axes[row, col]\n",
    "        \n",
    "        widths = stats['widths']\n",
    "        heights = stats['heights']\n",
    "        \n",
    "        # Scatter plot of width vs height\n",
    "        ax.scatter(widths, heights, alpha=0.6, s=50)\n",
    "        ax.set_xlabel('Width (pixels)', fontsize=11)\n",
    "        ax.set_ylabel('Height (pixels)', fontsize=11)\n",
    "        ax.set_title(component_name, fontsize=12, fontweight='bold')\n",
    "        ax.grid(alpha=0.3)\n",
    "        \n",
    "        # Add mean lines\n",
    "        ax.axvline(np.mean(widths), color='r', linestyle='--', alpha=0.7, label=f'Mean W: {np.mean(widths):.0f}')\n",
    "        ax.axhline(np.mean(heights), color='g', linestyle='--', alpha=0.7, label=f'Mean H: {np.mean(heights):.0f}')\n",
    "        ax.legend(fontsize=9)\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for idx in range(len(dimension_stats), 4):\n",
    "        row = idx // 2\n",
    "        col = idx % 2\n",
    "        axes[row, col].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ùå No dimension statistics available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b9db04",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£5Ô∏è‚É£ Analyze Pose JSON Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f88252b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sample_split:\n",
    "    pose_json_dir = split_path / 'openpose_json'\n",
    "    \n",
    "    if pose_json_dir.exists():\n",
    "        print(\"=\"*70)\n",
    "        print(\"ü¶¥ POSE JSON ANALYSIS\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        # Get sample JSON files\n",
    "        json_files = list(pose_json_dir.glob('*.json'))\n",
    "        \n",
    "        if json_files:\n",
    "            print(f\"\\n‚úÖ Found {len(json_files)} pose JSON files\")\n",
    "            \n",
    "            # Load and analyze a sample\n",
    "            sample_json = json_files[0]\n",
    "            print(f\"\\nüìÑ Sample JSON: {sample_json.name}\")\n",
    "            \n",
    "            with open(sample_json, 'r') as f:\n",
    "                pose_data = json.load(f)\n",
    "            \n",
    "            print(f\"\\nüìä JSON Structure:\")\n",
    "            print(f\"   Keys: {list(pose_data.keys())}\")\n",
    "            \n",
    "            if 'people' in pose_data:\n",
    "                print(f\"   Number of people detected: {len(pose_data['people'])}\")\n",
    "                \n",
    "                if pose_data['people']:\n",
    "                    person = pose_data['people'][0]\n",
    "                    print(f\"\\n   Person data keys: {list(person.keys())}\")\n",
    "                    \n",
    "                    if 'pose_keypoints_2d' in person:\n",
    "                        keypoints = person['pose_keypoints_2d']\n",
    "                        num_keypoints = len(keypoints) // 3  # x, y, confidence for each point\n",
    "                        print(f\"   Number of keypoints: {num_keypoints}\")\n",
    "                        print(f\"   Keypoints format: [x, y, confidence] √ó {num_keypoints}\")\n",
    "                        \n",
    "                        # Display first few keypoints\n",
    "                        print(f\"\\n   Sample keypoints (first 3):\")\n",
    "                        for i in range(min(3, num_keypoints)):\n",
    "                            x = keypoints[i*3]\n",
    "                            y = keypoints[i*3 + 1]\n",
    "                            conf = keypoints[i*3 + 2]\n",
    "                            print(f\"      Point {i}: x={x:.2f}, y={y:.2f}, confidence={conf:.3f}\")\n",
    "            \n",
    "            print(\"\\n\" + \"=\"*70)\n",
    "        else:\n",
    "            print(\"\\n‚ùå No JSON files found in pose directory\")\n",
    "    else:\n",
    "        print(\"\\n‚ùå Pose JSON directory not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4638116d",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£6Ô∏è‚É£ Create Side-by-Side Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33177696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comprehensive side-by-side visualization\n",
    "if person_images and cloth_images:\n",
    "    n_samples = 3\n",
    "    \n",
    "    fig, axes = plt.subplots(n_samples, 4, figsize=(20, 5 * n_samples))\n",
    "    fig.suptitle('Complete Data Pipeline Visualization', fontsize=18, fontweight='bold')\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        # Get corresponding files (same index)\n",
    "        person_path = person_images[i] if i < len(person_images) else person_images[0]\n",
    "        \n",
    "        # Load person image\n",
    "        person_img = Image.open(person_path)\n",
    "        axes[i, 0].imshow(person_img)\n",
    "        axes[i, 0].set_title(f'Person Image\\n{person_path.stem}', fontsize=11)\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        # Try to load corresponding cloth\n",
    "        if i < len(cloth_images):\n",
    "            cloth_path = cloth_images[i]\n",
    "            cloth_img = Image.open(cloth_path)\n",
    "            axes[i, 1].imshow(cloth_img)\n",
    "            axes[i, 1].set_title(f'Garment\\n{cloth_path.stem}', fontsize=11)\n",
    "        else:\n",
    "            axes[i, 1].text(0.5, 0.5, 'No Image', ha='center', va='center')\n",
    "        axes[i, 1].axis('off')\n",
    "        \n",
    "        # Try to load corresponding parse mask\n",
    "        if parse_images and i < len(parse_images):\n",
    "            parse_path = parse_images[i]\n",
    "            parse_img = Image.open(parse_path)\n",
    "            axes[i, 2].imshow(parse_img)\n",
    "            axes[i, 2].set_title(f'Segmentation\\n{parse_path.stem}', fontsize=11)\n",
    "        else:\n",
    "            axes[i, 2].text(0.5, 0.5, 'No Mask', ha='center', va='center')\n",
    "        axes[i, 2].axis('off')\n",
    "        \n",
    "        # Try to load corresponding pose\n",
    "        if pose_images and i < len(pose_images):\n",
    "            pose_path = pose_images[i]\n",
    "            pose_img = Image.open(pose_path)\n",
    "            axes[i, 3].imshow(pose_img)\n",
    "            axes[i, 3].set_title(f'Pose\\n{pose_path.stem}', fontsize=11)\n",
    "        else:\n",
    "            axes[i, 3].text(0.5, 0.5, 'No Pose', ha='center', va='center')\n",
    "        axes[i, 3].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"‚úÖ Complete data pipeline visualized!\")\n",
    "else:\n",
    "    print(\"‚ùå Insufficient data for complete visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2540bb4",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£7Ô∏è‚É£ Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f467cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data_integrity(split_path):\n",
    "    \"\"\"Check for missing or mismatched data\"\"\"\n",
    "    print(\"=\"*70)\n",
    "    print(\"üîç DATA INTEGRITY CHECK\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Get all component directories\n",
    "    components = {\n",
    "        'image': split_path / 'image',\n",
    "        'cloth': split_path / 'cloth',\n",
    "        'image-parse-v3': split_path / 'image-parse-v3',\n",
    "        'openpose_img': split_path / 'openpose_img',\n",
    "        'openpose_json': split_path / 'openpose_json',\n",
    "    }\n",
    "    \n",
    "    # Get filenames (without extensions) from each component\n",
    "    filenames = {}\n",
    "    for name, path in components.items():\n",
    "        if path.exists():\n",
    "            files = [f.stem for f in path.glob('*') if f.is_file()]\n",
    "            filenames[name] = set(files)\n",
    "            print(f\"\\n‚úÖ {name:20s}: {len(files):5d} files\")\n",
    "        else:\n",
    "            filenames[name] = set()\n",
    "            print(f\"\\n‚ùå {name:20s}: NOT FOUND\")\n",
    "    \n",
    "    # Check for consistency\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"üîó CONSISTENCY CHECK\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    if filenames['image']:\n",
    "        base_set = filenames['image']\n",
    "        print(f\"\\nüìä Using 'image' as reference: {len(base_set)} files\\n\")\n",
    "        \n",
    "        for name, file_set in filenames.items():\n",
    "            if name == 'image':\n",
    "                continue\n",
    "            \n",
    "            if file_set:\n",
    "                missing = base_set - file_set\n",
    "                extra = file_set - base_set\n",
    "                matching = len(base_set & file_set)\n",
    "                \n",
    "                print(f\"{name:20s}:\")\n",
    "                print(f\"   ‚úì Matching files:  {matching:5d}\")\n",
    "                if missing:\n",
    "                    print(f\"   ‚ö† Missing files:   {len(missing):5d}\")\n",
    "                if extra:\n",
    "                    print(f\"   ‚ö† Extra files:     {len(extra):5d}\")\n",
    "                if not missing and not extra:\n",
    "                    print(f\"   ‚úÖ Perfect match!\")\n",
    "                print()\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    return filenames\n",
    "\n",
    "if sample_split:\n",
    "    integrity_results = check_data_integrity(split_path)\n",
    "else:\n",
    "    print(\"‚ùå No data split available for integrity check\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1d2bc5",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£8Ô∏è‚É£ Key Findings & Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b582681",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"üí° KEY FINDINGS & INSIGHTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nüìä Dataset Summary:\")\n",
    "print(f\"   - Dataset: Zalando HD Resized (VITON-HD)\")\n",
    "print(f\"   - Location: {dataset_root}\")\n",
    "if dataset_stats:\n",
    "    for split_name, split_stats in dataset_stats.items():\n",
    "        total_components = sum(1 for s in split_stats.values() if s['count'] > 0)\n",
    "        print(f\"   - {split_name.capitalize()} split: {total_components} components found\")\n",
    "\n",
    "print(\"\\n‚úÖ Data Components Available:\")\n",
    "components_available = []\n",
    "if person_images:\n",
    "    components_available.append(\"Person images\")\n",
    "if cloth_images:\n",
    "    components_available.append(\"Garment images\")\n",
    "if parse_images:\n",
    "    components_available.append(\"Segmentation masks\")\n",
    "if pose_images:\n",
    "    components_available.append(\"Pose visualizations\")\n",
    "if sample_split and (split_path / 'openpose_json').exists():\n",
    "    components_available.append(\"Pose JSON keypoints\")\n",
    "\n",
    "for component in components_available:\n",
    "    print(f\"   ‚úì {component}\")\n",
    "\n",
    "print(\"\\nüìê Image Dimensions:\")\n",
    "if dimension_stats:\n",
    "    for component_name, stats in dimension_stats.items():\n",
    "        mean_w = np.mean(stats['widths'])\n",
    "        mean_h = np.mean(stats['heights'])\n",
    "        print(f\"   - {component_name}: ~{mean_w:.0f}√ó{mean_h:.0f} pixels\")\n",
    "\n",
    "print(\"\\nüéØ Recommendations for Preprocessing:\")\n",
    "print(\"   1. All images should be resized to consistent dimensions (e.g., 512√ó384 or 1024√ó768)\")\n",
    "print(\"   2. Verify person-garment pairing for training\")\n",
    "print(\"   3. Check segmentation mask quality for body parsing\")\n",
    "print(\"   4. Validate pose keypoints are correctly detected\")\n",
    "print(\"   5. Consider data augmentation (flip, rotation, color jitter)\")\n",
    "\n",
    "print(\"\\nüöÄ Next Steps:\")\n",
    "print(\"   1. Proceed to notebook 03_data_preprocessing.ipynb\")\n",
    "print(\"   2. Create preprocessing pipeline\")\n",
    "print(\"   3. Generate training/validation/test splits\")\n",
    "print(\"   4. Set up data loaders for model training\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\\n‚úÖ DATA EXPLORATION COMPLETE!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6cf6be",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£9Ô∏è‚É£ Save Exploration Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d05a438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save exploration report\n",
    "output_dir = project_root / 'outputs' / 'metrics'\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "report = {\n",
    "    'dataset_name': 'Zalando HD Resized (VITON-HD)',\n",
    "    'dataset_path': str(dataset_root),\n",
    "    'exploration_date': pd.Timestamp.now().isoformat(),\n",
    "    'splits': {},\n",
    "    'components_available': components_available,\n",
    "}\n",
    "\n",
    "# Add statistics\n",
    "for split_name, split_stats in dataset_stats.items():\n",
    "    report['splits'][split_name] = {\n",
    "        component: {\n",
    "            'count': stats['count'],\n",
    "            'size_mb': stats['size_mb']\n",
    "        }\n",
    "        for component, stats in split_stats.items()\n",
    "    }\n",
    "\n",
    "# Save as JSON\n",
    "report_path = output_dir / 'data_exploration_report.json'\n",
    "with open(report_path, 'w') as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Exploration report saved to: {report_path}\")\n",
    "\n",
    "# Also save summary DataFrame\n",
    "if not df_summary.empty:\n",
    "    csv_path = output_dir / 'data_summary.csv'\n",
    "    df_summary.to_csv(csv_path, index=False)\n",
    "    print(f\"‚úÖ Summary table saved to: {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c94d232",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìù Notes\n",
    "\n",
    "### Dataset Structure:\n",
    "\n",
    "The VITON-HD (Zalando HD Resized) dataset typically contains:\n",
    "- **Person images**: Full-body fashion model photos\n",
    "- **Garment images**: Flat-lay or product photos of clothing\n",
    "- **Segmentation masks**: Human parsing maps (body parts)\n",
    "- **Pose keypoints**: OpenPose format with body joint locations\n",
    "\n",
    "### Key Observations:\n",
    "\n",
    "1. **Image Quality**: Check if images are consistent in quality and resolution\n",
    "2. **Pose Variety**: Dataset should include diverse poses for robustness\n",
    "3. **Garment Types**: Variety of clothing types (shirts, dresses, etc.)\n",
    "4. **Data Completeness**: All components should have matching files\n",
    "\n",
    "### Common Issues:\n",
    "\n",
    "- **Missing Pairs**: Some person-garment pairs might be missing\n",
    "- **Inconsistent Dimensions**: Images may have different sizes\n",
    "- **Corrupted Files**: Some images might be unreadable\n",
    "- **Pose Detection Errors**: Some pose keypoints might be incorrect\n",
    "\n",
    "### Preprocessing Requirements:\n",
    "\n",
    "1. Resize all images to consistent dimensions\n",
    "2. Normalize pixel values\n",
    "3. Validate segmentation masks\n",
    "4. Filter out invalid pose detections\n",
    "5. Create train/validation/test splits\n",
    "\n",
    "---\n",
    "\n",
    "## üîó Useful Resources\n",
    "\n",
    "- [VITON-HD Paper](https://arxiv.org/abs/2103.16874)\n",
    "- [VITON-HD GitHub](https://github.com/shadow2496/VITON-HD)\n",
    "- [OpenPose Format](https://github.com/CMU-Perceptual-Computing-Lab/openpose)\n",
    "- [Human Parsing](https://github.com/GoGoDuck912/Self-Correction-Human-Parsing)\n",
    "\n",
    "---\n",
    "\n",
    "**Author**: Huzaifa Nasir  \n",
    "**Date**: December 2025  \n",
    "**Notebook**: 02_data_exploration.ipynb  \n",
    "**Status**: ‚úÖ Complete"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
